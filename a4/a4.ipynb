{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "name": "a4.ipynb",
   "provenance": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "x__t1uIZd139"
   },
   "source": [
    "# GitHub"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "cellView": "form",
    "id": "PehpfW10d14A",
    "outputId": "59c8614f-2464-4e92-d185-2263f03f1df5"
   },
   "source": [
    "#@markdown Cargar\n",
    "%cd ~\n",
    "%cd /content/\n",
    "uname = \"leinaxd\"\n",
    "!git config --global user.email '$uname@gmail.com'\n",
    "!git config --global user.name '$uname'\n",
    "\n",
    "from getpass import getpass\n",
    "password = getpass('Password:')\n",
    "!git clone https://$uname:$password@github.com/leinaxd/Tps/\n",
    "\n",
    "%cd Tps/a4"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/root\n",
      "/content\n",
      "Password:··········\n",
      "Cloning into 'Tps'...\n",
      "remote: Enumerating objects: 505, done.\u001B[K\n",
      "remote: Counting objects: 100% (505/505), done.\u001B[K\n",
      "remote: Compressing objects: 100% (371/371), done.\u001B[K\n",
      "remote: Total 505 (delta 256), reused 338 (delta 124), pack-reused 0\u001B[K\n",
      "Receiving objects: 100% (505/505), 77.32 MiB | 25.08 MiB/s, done.\n",
      "Resolving deltas: 100% (256/256), done.\n",
      "Checking out files: 100% (209/209), done.\n",
      "/content/Tps/a4\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E2DN-kWZd14C",
    "outputId": "9769c42c-ad4c-45bb-c760-0c6743178dc5"
   },
   "source": [
    "commit = \"a4: Init\" #@param {type:\"string\"}\n",
    "\n",
    "!git add .\n",
    "!git commit -m \"$commit\"\n",
    "!git push"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "[master 9d14652] a4: Init\n",
      " 1 file changed, 0 insertions(+), 0 deletions(-)\n",
      " create mode 100644 a4/imgs/arquitecturaNMT.jpg\n",
      "Counting objects: 5, done.\n",
      "Delta compression using up to 2 threads.\n",
      "Compressing objects: 100% (4/4), done.\n",
      "Writing objects: 100% (5/5), 88.55 KiB | 14.76 MiB/s, done.\n",
      "Total 5 (delta 2), reused 0 (delta 0)\n",
      "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001B[K\n",
      "To https://github.com/leinaxd/Tps/\n",
      "   4556817..9d14652  master -> master\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "cellView": "form",
    "id": "Mc8E2_i6d14D"
   },
   "source": [
    "#@markdown pull / update\n",
    "!git pull"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "Z3vHnNuLd14E"
   },
   "source": [
    "# CS224N Assignment 4: Neural Machine Translation with RNNs (45 + 30 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "gNPr6wj8d14E"
   },
   "source": [
    "Esta tarea se divide en dos partes: *Neural Machine Translation with RNNs* y *Analyzing NMT systems*. El primero es básicamente codificación y el segundo son preguntas escritas. Si te atoras en la primera sección, puedes trabajar en la segunda ya que las secciones son independientes.\n",
    "La notación e implementación de los *sistemas NMT* es tramposa. Recomendamos la lectura de Zhang, 2020. https:arxic.org/abs/2010.04791 para entender mejor la tarea de traducción *Cherokee-Inglés* que sirvió de inspiración para este proyecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEpOpuMDfBcR"
   },
   "source": [
    "## 1. Neural Machine Translation with RNNs (45 points)\n",
    "\n",
    "En *Machine Translation* el objetivo es convertir una oración desde un lenguaje *source*(Cherokee) hacia un lenguaje *target* (Inglés).<br>\n",
    "En este proyecto implementaremos un modelo neuronal **seq2seq** con **Atención**. En esta sección, describiremos el **procedimiento de entrenamiento** para el sistema **NMT** propuesto, el cual utiliza un **Encoder** **LSTM** **Bidireccional** y un **Decoder** **LSTM** **Unidireccional**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Ajj9oU_goY0"
   },
   "source": [
    "### Descripción del modelo (Procedimiento de aprendizaje)\n",
    "![modelo](https://github.com/leinaxd/Tps/raw/master/a4/imgs/arquitecturaNMT.jpg)\n",
    "Figura 1. Modelo seq2seq con Atención multiplicativa, mostrada en la tercera fase del decoder. Los estados ocultos $h_i^{enc}$ y los estados de las celdas $c_i^{enc}$ se definen a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Configurando la máquina virtual"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Implementación y preguntas escritas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Analizando el sistema NMT (30 points)\n",
    "\n",
    "En la parte 1 hemos modelado nuestro problema NMT a un *subword-level*. Esto es, dada una oración en el idioma de origen, encontramos los componentes a nivel *subword* desde la matriz de *embeddings*.\n",
    "Alternativamente podríamos haber modelado el problema NMT a nivel palabra, obervando palabras completas desde la matriz de *embeddings*.\n",
    "### a. Por qué modelar el sistema **NMT** bajo *subword-level* vs *word-level*? (2 points)\n",
    "**Pista**: El Cherokee es un idioma polysintético"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color =\"green\">\n",
    "\n",
    "</font>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "### b. Por qué las codificaciones (*Embeddings*) a nivel *letra* y *Subword* suelen ser más chicos que la codificación a nivel *palabra*? (2 points)\n",
    "Dar una razón en 1-2 oraciones."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color =\"green\">\n",
    "\n",
    "</font>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### c. Cómo ayuda el entrenamiento multilenguaje en mejorar el rendimiento sobre lenguajes de bajos recursos? (2 points)\n",
    "Un reto de entrenar modelos **NMT** exitosos es la carencia de datos del lenguaje, particularmente para lenguajes de recursos escasos como el Cherokee. Una forma de responder a este reto es mediante el entrenamiento multi-lenguaje, donde entrenamos nuestro modelo **NMT** sobre varios idiomas (incluyendo Cherokee). <br>\n",
    "Puedes leer más en https://ai.googleblog.com/2019/10/exploring-massively-multilingual.html"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<font color =\"green\">\n",
    "\n",
    "</font>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### d. (6 points)\n",
    "Aquí presentamos 3 ejemplos de errores encontrados en las salidas de nuestro modelo **NMT** (que es el mismo entrenado por tí). Los errores están subrayados.\n",
    "Por cada ejemplo de la oración de origen, referenciar la traducción a inglés y la traducción obtenida por el modelo.\n",
    "* Incluir las posibles razones que expliquen el error cometido por el modelo. (Tanto como su construcción lingüística o una limitación específica del modelo)\n",
    "* Describir una posible manera para corregir el error observado. Hay más de una manera de corregir un error. Por ejemplo, se podría ajustar el tamaño de la capa oculta o cambiando el mecanismo de atención.\n",
    "\n",
    "A continuación están las traducciones a analizar. Sólo analizar el error subrayado de cada oración. Se asegura que no tienes que saber Cherokee para responder estas preguntas. Pero si quieres saber un poco más de este lenguaje, sientete libre de consultar https://www.cherokeedictionary.net/ para buscar palabras.\n",
    "\n",
    "#### i. (2 points)\n",
    "**Origen de la traducción** (Source) = *Yona utsesdo anitsilvsgi digvtanv uwoduisdei* <br>\n",
    "**Traducción de referencia** *Fern had a crown of daisies in her hair*<br>\n",
    "**Traducción del modelo**: *Fern had <u>her hair</u> with her hair*\n",
    "#### ii. (2 points)\n",
    "**Origen de la traducción** (Source) = *Ulihelisdi nigalisda.* <br>\n",
    "**Traducción de referencia** *She is very excited.*<br>\n",
    "**Traducción del modelo**: *<u>it's</u> joy*\n",
    "#### iii. (2 points)\n",
    "**Origen de la traducción** (Source) = *Tsesdi hana yitsadawoesdi usdi atsadi!* <br>\n",
    "**Traducción de referencia** *Don't swim there, Littlefish!*<br>\n",
    "**Traducción del modelo**: *Don't know how <u>a small fish!</u>*\n",
    "\n",
    "### e. (4 points)\n",
    "Exploremos las salidas del modelo que hemos entrenado! Las traducciones del set de testeo producidas en el punto 1-i deberían encontrarse en\n",
    " `outputs/test_outputs.txt`.\n",
    "1. (2 points) Encontrar el límite donde las traducciones predichas son correctas para secuencias largas (4 o 5 palabras). Verificar el archivo destino *target* (Inglés).\n",
    "Contiene el archivo de entrenamiento ese texto (casi) literal? Si lo tiene o no, qué aprendió el sistema a hacer?\n",
    "2. (2 points) Encontrar el límite donde la traducción predicha comienza correcta durante una secuencia de 4 o 5 palabras, pero luego diverge (donde el final de la oración parece no tener sentido alguno). Qué dice esto sobre el comportamiento del decodificador?\n",
    "\n",
    "### f. (14 points)\n",
    "El puntaje **BLEU** es la métrica de evaluación automática más utilizada para sistemas **NMT**. Se suele calcular sobre el set de testeo completo, pero aquí consideraremos el puntaje para un solo ejemplo (*).\n",
    "Suponga que tenemos una oración de origen $\\mathbf{s}$, un conjunto de $k$ traducciones de referencia $\\mathbf{r_1 \\dots r_k}$ y una traducción candidata $\\mathbf{c}$.\n",
    "Para calcular el puntaje **BLEU** de $\\mathbf{c}$, primero debemos calcular la precisión n-grama modificada $p_n$ de $\\mathbf{c}$, para cada $n=1,2,3,4$ donde n es el n-grama.\n",
    "\n",
    "$p_n=\\frac{\\sum_{ngram\\in c} min(\n",
    "max_{i=1...k}(Count_{\\mathbf{r_i}} (n-gram), Count_{\\mathbf{c}} (n-gram))\n",
    ")}\n",
    "{\\sum_{ngram\\in c} Count_{\\mathbf{c}}(ngram)}$\n",
    "\n",
    "Aquí por cada n-grama que aparece en la traducción candidata $\\mathbf{c}$, contamos la máxima cantidad de veces que aparece en cualquiera traducción de referencia, limitado a la cantidad de veces que aparece en $\\mathbf{c}$ (este es el numerador). Dividimos este número por la cantidad de n-gramas en $\\mathbf{c}$ (denominador).\n",
    "\n",
    "(\\*) Esta definición de puntaje **BLEU** nivel oración coincide con la función `sentence_bleu()` en el paquete `nltk`. Observar que la función del NLTK es sensible a las mayúsculas. En esta pregunta, todo el texto está en minúsculas. https://www.nltk.org/api/nltk.translate.html#nltk.translate.bleu_score.sentence_bleu\n",
    "\n",
    "Luego, calculamos la *Brevity pealty* **BP**. <br>\n",
    "Sea $len(\\mathbf{c})$ la longitud de $\\mathbf{c}$ y sea $len(\\mathbf{r})$ la longitud de la traducción de referencia que es más cercana a $len(\\mathbf{c})$ (En el caso de dos referencias equidistantes, elegir $len(\\mathbf{r})$ como la más corta.)\n",
    "\n",
    "$ BP = \\begin{cases}\n",
    "1 \\hspace{10 mm} &si \\hspace{5mm} len(\\mathbf{c})\\ge len(\\mathbf{r}) \\\\\n",
    "exp(1-\\frac{len(\\mathbf{r})}{len (\\mathbf{c})})  &e.o.c.\n",
    "\\end{cases} $\n",
    "\n",
    "Finalmente, el puntaje **BLEU** para el candidato $\\mathbf{c}$ respecto a $\\mathbf{r_1 \\dots r_n}$ es:\n",
    "\n",
    "$BLEU = BP·exp(\\sum_{n=1}^4 \\lambda_n\\ log\\ p_{n})$\n",
    "\n",
    "Donde $\\lambda_1, \\lambda_2, \\lambda_3, \\lambda_4$ son pesos cuya suma es 1. El $log$ es el logaritmo natural."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### i. Considere el ejemplo en español. (5 points)\n",
    "Oración de **Origen**: **El amor todo lo puede**<br>\n",
    "Traducción de referencia $\\mathbf{r_1}$:     *Love can always find a way* <br>\n",
    "Traducción de referencia $\\mathbf{r_2}$:     *Love makes anything possible*<br>\n",
    "Modelo NMT $\\mathbf{c_1}$: *The love can always do* <br>\n",
    "Modelo NMT $\\mathbf{c_2}$: *love can make anything possible*\n",
    "\n",
    "* Calcule el puntaje **BLEU** para $\\mathbf{c_1}$ y $\\mathbf{c_2}$.\n",
    "Sea $\\lambda_i = 0.5$ para $i\\in \\{1,2\\}$ y $\\lambda_i = 0$ para $i\\in \\{3,4\\}$ (Esto significa ignorar los 3-gramas y 4-gramas. no calcular $p_3$ y $p_4$)\n",
    "Cuando se calculan los puntajes BLEU, mostrar tu trabajo (valores $p_1, p_2, len(\\mathbf{c}),len(\\mathbf{r}), BP$). Notar que los puntajes **BLEU** se pueden expresar entre 0 y 1, o entre 0 y 100. El código utiliza la escala 0-100, mientras que las preguntas utilizan la escala 0-1.\n",
    "\n",
    "Cuál de las dos traducciones se considera mejor según **BLEU**? Estás de acuerdo en que es la mejor traducción?\n",
    "\n",
    "ii. (5 points) Nuestro disco duro se ha corrompido y hemos perdido la traducción de referencia $\\mathbf{r_2}$. Por favor, recalcule el puntaje **BLEU** para $\\mathbf{c_1}$ y $\\mathbf{c_2}$, esta vez solamente respecto a $\\mathbf{r_1}$. Cuál de las dos traducciones recive un mayor puntaje? Estás de acuerdo en que es la mejor traducción?\n",
    "iii. (2 points) Por la disponibilidad de datos, los sistemas NMT suelen evaluarse respecto a una sola traducción de referencia. Explique por qué podría ser problemático.\n",
    "iv. (2 points) Enumerar dos ventajas y dos desventajas de **BLEU** comparado con la evaluación humana como métrica para *Machine Translation*"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ]
}