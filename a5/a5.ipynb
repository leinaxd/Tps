{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "a5.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leinaxd/Tps/blob/master/a5/a5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "4zY3aaibN4J3"
      },
      "source": [
        "# GitHub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "dDgiES8tN4J8"
      },
      "source": [
        "#@markdown Cargar\n",
        "%cd ~\n",
        "%cd /content/\n",
        "uname = \"leinaxd\"\n",
        "!git config --global user.email '$uname@gmail.com'\n",
        "!git config --global user.name '$uname'\n",
        "\n",
        "from getpass import getpass\n",
        "password = getpass('Password:')\n",
        "!git clone https://$uname:$password@github.com/leinaxd/Tps/\n",
        "\n",
        "%cd Tps/a5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "gkaf6DXMN4J-"
      },
      "source": [
        "commit = \"a5: Init\" #@param {type:\"string\"}\n",
        "\n",
        "!git add .\n",
        "!git commit -m \"$commit\"\n",
        "!git push"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ZiDwwu-7N4KJ"
      },
      "source": [
        "#@markdown pull / update\n",
        "!git pull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "HGACFxhkN4KK"
      },
      "source": [
        "# CS224N Assignment 5: Self-Attention, Transformers and Pretraining (21 + 35 + 5 Points)\n",
        "\n",
        "---\n",
        "Nota. Hay diferentes cuestiones a tener a la hora de realizar este proyecto\n",
        "\n",
        "* Hay preguntas de deducciones matemáticas\n",
        "* La cantidad de código pytorch, y complejidad del código en este proyecto es mucho menor que en el proyecto 4. Sin embargo, se le dará menor seguimiento y menor andamiaje para escribir el código.\n",
        "* Este proyecto incluye un paso de pre-entrenamiento que toma aproximadamente 2 horas a realizar en Azure, y tendrás que escribirlo dos veces.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "-79T2Iy-N4KL"
      },
      "source": [
        "Este proyecto se trata de una investigación sobre los bloques y los efectos del entrenamiento de *self-attention* y *Transformers*.\n",
        "Esto cubre las propiedades matemáticas mediante preguntas escritas.\n",
        "Además, obtendrás experiencia sobre la construcción de sistemas prácticos mediante el repropósito del *codebase*.\n",
        "\n",
        "El trabajo se divide en una parte matemática escrita y una parte de codificación, con su propio conjunto de preguntas escritas.\n",
        "\n",
        "Aquí un pequeño resumen\n",
        "\n",
        "1. **Exploración matematica**: Qué clase de operaciones puede implementar sencillamente *self-attention*? Por qué deberíamos utilizar cosas mas bellas como *multi-head self attention*?\n",
        "Esta sección utilizará cierta investigación matemática para iluminar algunas de las motivaciones de las redes de *self-attention* y *Transofmers*.\n",
        "2. **Extendiendo el codebase investigado**: En esta parte del trabajo, obtendrás cierta experiencia e intuición sobre las investigaciones más filosas en NLP.\n",
        "Enseñar a los modelos NLP los hechos del mundo mediante *Pretraining* y acceso al conocimiento mediante un ajuste fino.\n",
        "Entrenarás un modelo *Transformer* para intentar responder preguntas sencillas de la forma *\"Donde ha nacido la persona [x]?\"* Sin proveer ningún texto de entrada del cual extraer la respuesta.\n",
        "Encontrarás que los modelos son capaces de aprender muchos Hechos sobre donde ha nacido las personas mediante el preentrenamiento y acceder a esta información durante el ajuste fino para responder estas preguntas.\n",
        "\n",
        "Luego observarás detenidamente al sistema construído y razonarás sobre las implicaciones y responsabilidades sobre tal conocimiento implícito."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "CZj4CcdpN4KM"
      },
      "source": [
        "## 1. Attention Exploration (21 points)\n",
        "El *self-attention Multi-Headed* es el componende del núcleo en los *Transformers*. En esta pregunta, obtendrás cierta práctica trabajando con las ecuaciones de *self-attention*, que motivarán a preguntarse Por qué *Muliti-Headed self-Attention* es preferible frente a *single-headed self-attention*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "R51_g6SaN4KO"
      },
      "source": [
        "### a. Copiado en Atención (2 points)\n",
        "Recuerde que la atención, podría ser vista como una operación sobre una secuencia *Querry* $q\\in \\mathbb{R}^d$, un conjunto de vectores evaluados $\\{v_1\\dots v_n\\},\\hspace{5mm} v_i\\in \\mathbb{R}^d$ y un conjunto de vectores de dirección *Keys* $\\{k_1 \\dots k_n\\},\\hspace{5mm}k_i\\in \\mathbb{R}^d$ especificado según:\n",
        "\n",
        "$\\begin{align}\n",
        "c&= \\sum_{i=1}^n v_i \\alpha_i\\\\\n",
        "\\alpha_i &= \\frac{exp(k_i^T\\ q)}{\\sum_{j=1}^n exp(k_j^T\\ q)}\n",
        "\\end{align}$\n",
        "\n",
        "Donde $\\alpha_i$ es comunmente llamado \"Los pesos de Atención\" y las salidas $c\\in \\mathbb{R}^d$ su correspondiente promedio ponderado sobre los valores de los vectores. <br>\n",
        "\n",
        "* Primero mostraremos que para la *Atención* es particularmente simple \"Copiar\" un valor del vector de salida $c$.\n",
        "\n",
        "Describa (en una oración) qué propiedades, de la entrada de  atención, consiguen que la salida $c$ sea aproximadamente igual a $v_j$ para algún $j\\in \\{1\\dots n\\}$.\n",
        "\n",
        "Específicamente, qué debe ser cierto sobre la secuencia $q$, los valores $\\{v_1\\dots v_n\\}$ y/o las *keys* $\\{k_1\\dots k_n\\}$?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27fGgk3LuSq4"
      },
      "source": [
        "<font color =\"yellow\">\n",
        "Para que $c\\approx v_j$, el coeficiente de atención $\\alpha_j$ para dicho vector debe ser cercano a 1 y el resto de coeficientes cercanos a 0</font></br>\n",
        "<font color = \"pink\">\n",
        "Para que esto ocurra, $k_j^T q$ debe ser más grande que el resto de vectores $k_i$</font></br>\n",
        "<font color = \"orange\">\n",
        "Es por ello, que el vector Key $k_j$ representa la información de $v_j$</font></br>\n",
        "<font color = \"violet\"> \n",
        "Finalmente, se consigue copiar la entrada $v_j$ cuando\n",
        "$q = k_j$\n",
        "</font></br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "dns_Wux9N4KP"
      },
      "source": [
        "### b. Un promedio de 2 (4 points)\n",
        "Considere el conjunto de vectores *keys* $\\{k_1 \\dots k_n\\}$ donde todos los vectores *key* son perpendiculares, esto es que $k_i \\perp k_j\\hspace{5mm} \\forall i\\neq j$. Sea $||k_i||=1\\hspace{5mm} \\forall i$. \n",
        "\n",
        "Sea $\\{v_1 \\dots v_n\\}$ el conjunto arbitrario de vectores evaluados. \n",
        "\n",
        "Sea $v_a,\\ v_b\\in \\{v_1\\dots v_n\\}$ dos vectores. \n",
        "\n",
        "Dar una expresión para el vector de querry $q$ tal que la salida $c$ es aproximadamente igual al promedio entre $v_a$ y $v_b$ esto es $\\frac{1}{2}(v_a+v_b)$.\n",
        "Observar que puedes referenciar el correspondiente vector clave *key* de $v_a$ y $v_b$ como $k_a$ y $k_b$ respectivamente.\n",
        "\n",
        "* Pista: Mientras que la función softmax nunca promediará exactamente 2 vectores, puedes aproximarte utilizando un múltiplo escalar grande en la expresión"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSoA4ozOQIi2"
      },
      "source": [
        "<font color = \"yellow\"> \n",
        "Si quiero que \n",
        "$c=\\sum_{i=1}^n \\alpha_i v_i \\approx \\frac{v_a+v_b}{2}$\n",
        "</font></br>\n",
        "<font color = \"pink\"> \n",
        "Entonces\n",
        "$\\alpha_a = \\frac{1}{2}\\ \\ y\\ \\ \\alpha_b = \\frac{1}{2}$\n",
        "</font></br>\n",
        "<font color = \"orange\"> \n",
        "Entonces\n",
        "$exp(k_a^T\\ q) \\approx exp(k_b^T\\ q)$\n",
        "</font></br>\n",
        "<font color = \"violet\"> \n",
        "Finalmente si\n",
        "$q = \\frac{k_a + k_b}{2}$ \n",
        "Entonces la salida será un promedio de los vectores $v_a\\ y\\ v_b$\n",
        "</font></br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "OlvroBjqN4Ke"
      },
      "source": [
        "### c. Desventajas de la atención de una cabezal (5 points)\n",
        "En la parte anterior, hemos visto cómo era posible con un solo cabezal atender equitativamente dos valores. \n",
        "El mismo concepto podría facilmente extenderse para cualquier conjunto de valores. En esta pregunta veremos qué esto no es una solucíón práctica.\n",
        "\n",
        "Considere el conjunto de vectores clave *keys* $\\{k_1\\dots k_n\\}$ que fueron muestreados aleatoriamente de $k_i\\sim N(\\mu_i, \\Sigma_i)$ donde la media $\\mu_i$ es conocida pero la covarianza $\\Sigma_i$ no lo es. Además, asuma que las medias $\\mu_i$ son perpendiculares, es decir $\\mu_i^T\\ \\mu_j = 0\\hspace{5mm} si\\ \\ i\\neq j$ y son de norma unitaria $||\\mu_i|| = 1 $.\n",
        "\n",
        "i. (2 points) Asuma que las matrices de Covarianza son $\\Sigma_i = \\alpha I$ para $\\alpha$ evanescentemente pequeño. Diseñe una secuencia $q$ en términos de $\\mu_i$ tal como antes $c\\approx \\frac{1}{2}(v_a+v_b)$ y provea un breve argumento de por qué funciona."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwUdiMJ68Af6"
      },
      "source": [
        "<font color=\"yellow\">\n",
        "i. Si $q = \\frac{\\mu_a + \\mu_b}{2}$\n",
        "</font></br>\n",
        "<font color = \"orange\">\n",
        "$E[k_i^T\\ q]=E[k_i^T]\\ q =\\mu_i\\ \\frac{\\mu_a + \\mu_b}{2} = \\begin{cases}\n",
        "\\frac{\\mu_a^2}{2}&\\ si\\ i=a\\\\\n",
        "\\frac{\\mu_b^2}{2}&\\ si\\ i=b\\\\\n",
        "0&\\ eoc\n",
        "\\end{cases}\n",
        "$\n",
        "</font></br>\n",
        "\n",
        "<font color = \"lightblue\">\n",
        "$E[\\alpha_i] = E[\\frac{exp(k_i^T\\ q)}{\\sum_{j=1}^n exp(k_j^T\\ q)}] =\\frac{1}{\\sum_{j=1}^n exp(k_j^T\\ q)} E[exp(k_i^T\\ q)]$\n",
        "</font></br>\n",
        "<font color =\"lightgreen\">La función característica se define:\n",
        "$$\\phi_X(t) = E[exp(i\\ t\\ X)]$$\n",
        "Para el caso normal multivariable:\n",
        "$$\\phi_X(t) = exp(t^T(i\\ \\mu - 0.5\\Sigma \\ t)$$\n",
        "</font></br>\n",
        "<font color = \"lightblue\">\n",
        "En nuestro caso, para t = 1:\n",
        "$$X_i = \\frac{k_i^T\\ q}{i\\ t}$$\n",
        "$$E[X_i] = \\mu_i^T \\frac{\\mu_a+\\mu_b}{2 t\\ i}$$\n",
        "$$Var(X_i) = E[X_i^2]-E^2[X_i] = Var(k_i)\\ \\frac{q^2}{- t^2}$$\n",
        "$$E[exp(k_i^T\\ q)] = exp(t^T(\\mu_i^T\\frac{\\mu_a + \\mu_b}{2t}-0.5 t^T\\Sigma_i \\frac{q^2}{-t^2}t))$$\n",
        "</font></br>\n",
        "<font color=\"pink\">\n",
        "Aproximando con $\\Sigma_i\\rightarrow \\infty$\n",
        "$$E[\\alpha_i]=\\frac{exp(\\mu_i^T\\ \\frac{\\mu_a+\\mu_b}{2})}{\\sum_{i=1}^n exp(k_j^T\\ q)}$$\n",
        "$$E[\\alpha_a]=E[\\alpha_b]=\\frac{exp(\\frac{1}{2})}{\\sum_{i=1}^n exp(k_j^T\\ q)}$$\n",
        "$$E[\\alpha_{i\\neq a,b}] = 0$$\n",
        "</font></br>\n",
        "<font color=\"violet\">\n",
        "Finalmente\n",
        "$$E[c] = E[\\sum_{i=1}^n \\alpha_i v_i]=\\sum_{i=1}^n E[\\alpha_i v_i]$$\n",
        "si asumimos $\\alpha_i$, $v_i$ descorrelacionados:\n",
        "$$E[c] = \\sum_{i=1}^n E[\\alpha_i]E[v_i]=\\frac{E[v_a] + E[v_b]}{2}$$\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bzFoCUQ8eMz"
      },
      "source": [
        "ii. (3 points) Aunque la atención de cabezal simple es resistente a pequeñas perturbaciones en sus *keys* algunos tipos de perturbaciones más grandes podrían mostrar un inconveniente mayor. \n",
        "\n",
        "Específicamente, en muchos casos, un vector clave $k_a$ pordría ser mayor o menor en norma que otros, mientras que continúa apuntando en la misma dirección que $\\pi_a$. Como ejemplo, considere la covarianza para el item a como $\\Sigma_a = \\alpha \\ I +\\frac{1}{2}(\\mu_a\\ \\mu_a^T)$ para $\\alpha$ evanescentemente pequeño (como se ilustra en la figura 1). Además, sea $\\Sigma_i = \\alpha \\ I\\hspace{5mm} \\forall i\\neq a$.\n",
        "\n",
        "Cuando muestreas $\\{k_1 \\dots k_n\\}$ múltiples veces utilizando el vector $q$ definido en la parte (i), Cómo esperas, cualitativamente, que se vea el vector $c$ para diferentes muestras?\n",
        "\n",
        "![Figura 1](https://github.com/leinaxd/Tps/raw/master/a5/imgs/mu_vector.jpg)\n",
        "\n",
        "Figura 1. El vector $\\mu_a$ (mostrado en 2D como ejemplo) donde el rango de posibles valores de $k_a$ se observan en rojo. Como se mencionó anteriormente, $k_a$ apunta fuertemente en la misma dirección que $\\mu_a$ pero podría tener una mayor o menor magnitud."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeoSyPSE8fyj"
      },
      "source": [
        "<font color = \"yellow\">\n",
        "ii. Si $$k_a\\sim \\mathcal{N}(\\mu_a, \\alpha I+\\frac{1}{2}(\\mu_a\\ \\mu_a^T))$$\n",
        "y $$k_{i\\neq a}\\sim \\mathcal{N}(\\mu_i, \\alpha I)$$\n",
        "\n",
        "Si \n",
        "$$q = \\frac{\\mu_a + \\mu_b}{2}$$\n",
        "</font></br>\n",
        "<font color=\"lightblue\">\n",
        "Cuando haga: $k_i^T\\ q$ </br>\n",
        "Para $i\\neq a,b$\n",
        "$$E[k_i^T\\ q] = 0$$\n",
        "Para $i = b$\n",
        "$$E[k_b^T\\ q] = \\frac{\\mu_b^2}{2}$$\n",
        "Para $i = a$\n",
        "$$E[k_a^T\\ q] = \\frac{\\mu_a^2}{2}$$\n",
        "</font></br>\n",
        "<font color=\"pink\">\n",
        "Para $i\\neq a,b$\n",
        "$$E[\\alpha_i]=\\frac{E[exp(k_i^T\\ q)]}{\\sum_{i=1}^n exp(k_i^T\\ q)}\\approx 0$$\n",
        "<br>\n",
        "\\begin{align}\n",
        "E[c]&=E[\\frac{exp(k_a^T\\ q)}{exp(k_a^T\\ q) + exp(k_b^t\\ q)}v_a + \\frac{exp(k_b^T\\ q)}{exp(k_a^T\\ q) + exp(k_b^t\\ q)}v_b ]\\\\\n",
        "&= E[\\frac{1}{1 + exp(k_b^T\\ q - k_a^T\\ q)}v_a + \\frac{1}{exp(k_a^T\\ q - k_b^T\\ q) + 1}v_b]\\\\\n",
        "&=E[\\frac{1}{1 + exp((k_b^T-k_a^T)\\ q)}v_a + \\frac{1}{1+exp((k_a^T-k_b^T)\\ q)}v_b]\\\\\n",
        "\\end{align}\n",
        "Cualitativamente, si $k_b>>k_a$ se esperará que $c$ sea similiar a $v_a$, caso contrario será similar a $v_b$.\n",
        "</font></br>\n",
        "<font color=\"violet\">\n",
        "Cuando se muestree $k_i$, con baja varianza, la proyección\n",
        "$k_i^T q$ será nula. \n",
        "Esto quiere decir que el key i, no tiene la información que $q$ necesita.</br>\n",
        "Cuando se muestrea el key $k_b$; como $q$ tiene una parte de $\\mu_b$ entonces </br>\n",
        "$c \\approx v_b$ \n",
        "</font><br>\n",
        "<font color=\"orange\">\n",
        "Pero cuando se muestree de $k_a$, puede resultar que $k_a \\approx \\mu_a$ como estar bastante alejado.\n",
        "</br>\n",
        "Por ende, $c$ no copiará perfectamente a $v_a$, sinó que le asignará un valor más pequeño del que debería y la otra parte se lo llevará $v_b$.\n",
        "<br>\n",
        "Es decir $c\\approx \\alpha\\ v_a + (1-\\alpha) v_b$\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "CT4QWB3vN4Ke"
      },
      "source": [
        "### d. Beneficios de la atención multi-headed (3 points)\n",
        "Ahora veremos algo sobre el poder de la atención multicabeza. Considere una versión del *single-headed* self-attention como el ya presentado, excepto que tiene dos vectores de secuencia $q_1$ y $q_2$. \n",
        "\n",
        "Esto lleva a un par de vectores $c_1$ y $c_2$ cada uno la salida de una atención *single-headed* dados sus respectivos vectores de secuencia.\n",
        "La salida final de la atención *multi-headed* es su promedio $\\frac{1}{2}(c_1 + c_2)$. \n",
        "\n",
        "Como en la pregunta (1.c) considere el conjunto de vectores *key* $\\{k_1\\dots k_n\\}$ muestreados según $k_i\\sim N(\\mu_i, \\Sigma_i)$. Con media $\\mu_i$ es conocida pero covarianza $\\Sigma_i$ no.\n",
        "\n",
        "También como antes, asuma que las medias son mutuamente ortogonales: $\\mu_i^T \\mu_j = 0\\hspace{5mm}si\\ i\\neq j$ y de norma unitaria $||\\mu_i|| = 1$.\n",
        "\n",
        "i. (1 point) Asuma que las matrices de covarianza son $\\Sigma_i = \\alpha I$ para $\\alpha$ evanescentemente pequeño. Diseñe $q_1$ y $q_2$ tal que $c$ es aproximadamente igual a $\\frac{1}{2}(v_a + v_b)$.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB2n1sIF-IBL"
      },
      "source": [
        "<font color = \"yellow\">\n",
        "i. \n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWsDj_iN-IaL"
      },
      "source": [
        "ii. (2 points) Asuma que las matrices de covarianza son $\\Sigma_a = \\alpha\\ I + \\frac{1}{2}(\\mu_a^T \\mu_a)$ para $\\alpha$ evanescentemente pequeño y $\\Sigma_i = \\alpha\\ I\\hspace{5mm} \\forall i\\neq a$.\n",
        "Tomar los vectores de secuencia $q_1$ y $q_2$ tal cual fueron diseñados en la parte (i).\n",
        "Cualitativamente, Qué salida $c$ esperas obtener a través de diferentes muestras de vectores clave? Explique brevemente por qué. Puedes ignorar los casos donde $q_i^T\\ k_a<0$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "iz9hd1zBN4Kf"
      },
      "source": [
        "### e. *self-attention* *Key-Query-Value* en redes neuronales\n",
        "Hasta ahora, hemos discutido la atención como una función sobre un conjunto de vectores clave, un conjunto de vectores con valores y un vector de secuencia. En los *Transoformers* realizamos *self-attention* que crudamente signfica que dibujamos las claves, valores y secuencias de los mismos datos. Con mayor precisión, sea $\\{x_1 \\dots x_n\\}$ una secuencia de vectores en $\\mathbb{R}^d$. Piense a cada $x_i$ como la representante de la palabra $i$ en la oración. Una forma de *self-attention* defina a las claves, valores y secuencias como sigue.\n",
        "Sean las matrices de parámetros $V,\\ K,\\ Q\\ \\in \\mathbb{R}^{d\\times d}$, luego:\n",
        "\n",
        "$\\begin{align}\n",
        "v_i &= V \\ x_i\\hspace{5mm} &&i \\in \\{1\\dots n\\}\\\\\n",
        "k_i &= K \\ x_i\\hspace{5mm} &&i \\in \\{1\\dots n\\}\\\\\n",
        "q_i &= Q \\ x_i\\hspace{5mm} &&i \\in \\{1\\dots n\\}\\\\\n",
        "\\end{align}$\n",
        "\n",
        "Luego obtenemos el vector de contexto para cada entrada $i$: Tenemos $c_i=\\sum_{j=1}^n \\alpha_{ij}\\ v_j$, donde $\\alpha_{ij}$ es definida por $\\alpha_{ij}=\\frac{exp(k_j^T\\ q_i)}{\\sum_{l=1}^n exp(k_l^T\\ q_i)}$ Observar que esto es un *single-headed* *self-attention*.\n",
        "En esta pregunta mostraremos cómo la atención *key-value-query* como esta le permite a la red utilizar diferentes características de los vectores de entrada $x_i$ en cómo define las claves, secuencias y valores. Intuitivamente esto le permite a las redes elegir diferentes características de $x_i$ para ser el \"contenido\" (vector de valores) contra aquello que utiliza para determinar \"donde mirar\" por contenido (claves y secuencias)\n",
        "\n",
        "i. (3 points) Primero considere si no tuviesemos la atención \"keq-querry-value\". Para las claves, secuencias y valores utilizaremos directamente $x_i$, esto es $v_i=q_i=k_i=x_i$. Consideremos un conjunto específico de $x_i$, en particular, sean $u_a,\\ u_b,\\ u_c,\\ u_d$ vectores mutuamente ortogonales en $\\mathbb{R}^d$ cada uno con misma norma $||u_a|| = ||u_b|| = ||u_c|| = ||u_d|| = \\beta$, donde $\\beta$ es grande. Ahora sea nuestro $x_i$ tal que\n",
        "\n",
        "$\\begin{align}\n",
        "x_1 &=u_d + u_b\\\\\n",
        "x_2 &= u_a\\\\\n",
        "x_3 &= u_c + u_b\n",
        "\\end{align}$\n",
        "\n",
        "Si aplicamos *self-attention* con estos vectores, a qué vector se aproxima $c_2$? Será posible que $c_2$ se aproxime a $u_b$ añadiendo tanto a $u_d$ o $u_c$ a $x_2$? Explique por qué o por qué no.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NNS6BIM9tik"
      },
      "source": [
        "<font color=\"yellow\">\n",
        "i. \n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3Ngtijw9t-i"
      },
      "source": [
        "ii. (4 points) Ahora considere utilizar la atención *key-query-value* como se definió originalmente, utilizando las mismas definiciones para $x_1,\\ x_2$ y $x_3$ como en la parte (i), especifique las matrices $K,Q,V$ tal que $c_2\\approx u_b$ y $c_1 \\approx u_b-u_c$. Hay muchas soluciones a este problema, por lo que será fácil para tí. Si primero encuentras una $V$ tal que $v_1=u_b$ y $v_3=u_b-u_c$ luego trabajar en $Q$ y $K$.\n",
        "Algunas propiedades del producto externo podrían ser útiles.\n",
        "Para vectores ortogonales $u,v,w\\in \\mathbb{R}^d$ el producto externo $u\\ v^T$ es una matriz de $\\mathbb{R}^{d\\times d}$ y $(u\\ v^T)v = u(v^T\\ v)= u ||v||_2^2$ y $(u\\ v^T)w = u(v^T\\ w) = u·0$ (La última igualdad se debe a que $v$ y $w$ son ortogonales)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8yQumfmEtvH"
      },
      "source": [
        "## Pretrained Transformers Models and Knowledge Access (35 points)\n",
        "\n",
        "En este punto, entrenarás un modelo de Transformer que realizará una tarea de acceso al conocimiento del mundo. Conocimiento que no es proporcionado al entrenar el modelo. (Al menos si quisieras generalizar por fuera del set de entrenamiento)\n",
        "\n",
        "Encontrarás que mas o menos fallará la tarea. A continación, aprenderás a pre-entrenar el modelo utilizando texto de Wikipedia, y calibrando el modelo sobre la misma tarea, se le permitirá al modelo acceder al conocimiento de la etapa de pre-entrenamiento.\n",
        "De esta forma el modelo rendirá considerablemente mejor, sobre los datos de desarrollo (development)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q62yONI8GGcG"
      },
      "source": [
        "El código provisto es un *fork* de Andrej Karphaty [minGPT](https://github.com/kaparthy/minGPT). Es más amigable que la mayoría de los códigos de investigadores y es suficientemente simple y transparente. La parte \"GPT\" de minGPT corresponde al modelo de Transofmer de openAI descripto en [Este Paper](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf)\n",
        "\n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HizoVnCCHJg5"
      },
      "source": [
        "Como en los proyectos anteriores, desarrollaras el código localmente y luego entrenarás en Azure. Se utilizará el mismo entorno conda que el proyecto anterior y el mismo proceso de entrenamiento. Específicamente, ejecutarás \"conda activate py37_pytorch\" en la máquina de Azure. \n",
        "\n",
        "Requerirá aproximadamente 5hs de entrenamiento, por lo que debes administrar bien el tiempo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSDigcsYHqi5"
      },
      "source": [
        "El flujo de trabajo es el siguiente:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0gF6pLCHtrC"
      },
      "source": [
        "### a. (0 points) Probar la demostración\n",
        "\n",
        "En la carpeta `mingpt-demo/` hay un notebook que entrena y muestrea un modelo de lenguaje Transormer.\n",
        "\n",
        "Echarle un vistazo, para familiarizarse sobre cómo define y entrena el modelo. Mucho del código que escribas estará inspirado en ese archivo.\n",
        "\n",
        "**OBS**. Para esta tarea, no debes escribir código ni responder preguntas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZonF8zpImpL"
      },
      "source": [
        "### b. (0 points) Lectura de **NameDataset**, nuestro dataset de pares de nombre y lugar de nacimiento\n",
        "\n",
        "La tarea trata de acceder al lugar de nacimiento de una notable persona, escrita en Wikipedia. Creemos que es una forma particularmente simple de un Question Answering.\n",
        "\n",
        "Q: *Where was \\<person\\> was?*\n",
        "\n",
        "A: \\<*place*\\>\n",
        "\n",
        "* A partir de ahora, trabajaremos en el directorio `src/`.\n",
        "\n",
        "* El código en `mingpt-demo/` no será evaluado para esta tarea.\n",
        "\n",
        "* En `dataset.py` encontrarás la clase **NameDataset** que lee un archivo TSV (tab-separed values) de pares (nombre/lugar) y produce ejemplos para alimentar nuestro modelo Transformer.\n",
        "\n",
        "Para tener una noción de los ejemplos que estaremos trabajando, si ejecutas el código a continuación, cargará tu **NameDataset** en el conjunto de entrenamiento `birth_places_train.tsv` e imprimirá algunos ejemplos.\n",
        "\n",
        "`python src/dataset.py namedata`\n",
        "\n",
        "**Obs**. Para este punto, no hay que escribir código o responder preguntas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTm09FwYLUp8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brOlwfJZLU21"
      },
      "source": [
        "### c. (0 points) Implementar finetunning (Sin entrenamiento)\n",
        "\n",
        "Echar un vistazo a `run.py` Tiene cierto código esqueleto especificando banderas que eventualmente utilizarás como comandos de línea.\n",
        "\n",
        "En particular, querrás *pre-entrenar*, *calibrar finamente* o evaluar el código con este código.\n",
        "\n",
        "Por ahora, nos centraremos en la función de  calibración fina, para el caso \"sin pre-entrenamiento\".\n",
        "\n",
        "Inspirandonos sobre el código de entrenamiento en `play_char.ipynb`, escribir el código para calibrar el modelo de transformer sobre el dataset nombre/lugar de nacimiento, mediante ejemplos de la clase **NameDataset**.\n",
        "\n",
        "Por ahora, implemente el caso \"sin pre-entrenamiento\" (crear el modelo de la nada y entrenarlo sobre la tarea de predicción de la parte (b)).\n",
        "\n",
        "Tendrás que modificar 2 secciones, marcadas [parte c] en el código. Una es la de inicializar el modelo y la otra ajustarlo finamente.\n",
        "\n",
        "**Obs**. Solo debes inicializar el modelo en el caso etiquetado \"vainilla\" (luego en la sección g exploraremos una variante)\n",
        "\n",
        "Utilice los hiperparámetros del entrenador especificados en el código `run.py`\n",
        "\n",
        "Además echarle un vistazo al código de evaluación que ha sido implementado por tí. \n",
        "* Muestrea predicciones del modelo entrenado\n",
        "* y llama a `evaluate_places()`\n",
        "* para obtener el porcentaje total de lugares correctamente predichos.\n",
        "Ejecutarás este código en la parte (d) al evaluar tus modelos entrenados.\n",
        "\n",
        "Este es un paso intermedio para después, incluyendo la Parte d, que consiste en comandos que puedes ejecutar para verificar tu implementación. \n",
        "\n",
        "No se piden respuestas escritas en esta tarea."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZC11m9kXOkLd"
      },
      "source": [
        "### d. (5 points) Hacer predicciones (sin entrenamiento)\n",
        "\n",
        "Entrene su modelo de `wiki_places_train.tsv` y evalúe en `birth_dev.tsv`. Específicamente, deberías ser capaz de ejecutar los siguientes 3 comandos:\n",
        "\n",
        "```\n",
        "#Train on the names dataset\n",
        "python src/run.py finetune vanilla wiki.txt \\\n",
        "    --writing_params_path vanilla.model.params \\\n",
        "    --finetune_corpus_path birth_places_train.tsv\n",
        "\n",
        "#Evaluate on the dev set, writing out predictions\n",
        "python src/run.py evaluate vanilla wiki.txt \\\n",
        "    --reading_params_path vanilla.model.params \\\n",
        "    --eval_corpus_path birth_dev.tsv \\\n",
        "    --outputs_path vanilla.nopretrain.dev.predictions\n",
        "\n",
        "#Evaluate on the test set, writing out predictions\n",
        "python src/run.py evaluate vanilla wiki.txt \\\n",
        "    --reading_params_path vanilla.model.params \\\n",
        "    --eval_corpus_path birth_test_inputs.tsv \\\n",
        "    --outputs_path vanilla.nopretrain.test.predictions\n",
        "```\n",
        "El entrenamiento llevará menos de 10 minutos (en Azure). Reportar el Accuracy de tu modelo en el set de desarrollo dev. \n",
        "\n",
        "No se sorprenda si se encuentra inferior al 10%, entraremos en detalle en la parte 3. \n",
        "\n",
        "Como punto de referencia, también querremos calcular el Accuracy del modelo cuando se predice por \"Londres\" para lugar de nacimiento en el set de desarrollo *dev*.\n",
        "\n",
        "Llene `london_baseline.py` para calcular el Accuracy de este enfoque y reporte su resultado en un escrito. \n",
        "\n",
        "Debes considerar el código existente sea unas pocas líneas de largo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kVIHytBVac4"
      },
      "source": [
        "### e. (10 points) Defina la función **span_corruption** para preentrenamiento\n",
        "\n",
        "En el archivo `src/dataset.py`, implemente la función `__get_item__()` para la clase de dataset  CharCorruptionDataset.\n",
        "\n",
        "Siga las instrucciones provistas en los comentarios de `dataset.py`.\n",
        "\n",
        "SpanCorruption es explorada en el siguiente [paper](https://arxiv.org/pdf/1910.10683.pdf). Que aleatoriamente selecciona trozos de texto en el documento y los reemplaza con unos símbolos únicos (noising).\n",
        "\n",
        "Los modelos toman este texto con ruido y se les exige que saquen un patrón para cada centinela seguido de los símbolos que fueron sustituídos por tal centinela en la entrada.\n",
        "\n",
        "En esta pregunta, implementarás una simplificación que solamente enmascara una simple secuencia de caracteres.\n",
        "\n",
        "Esta pregunta será evaluada con Autograder basada en si la función de span de corrupción implementa algunas propiedades básicas de nuestra implementación. \n",
        "Instanciaremos el CharCorruptionDataset con nuestros propios datos y obtendremos ejemplos de él.\n",
        "\n",
        "Para ayudar a debuggear, la siguiente línea muestreará algunos ejemplos de tu CharCorruptionDataset sobre el dataset de preentrenamiento, wiki.txt, y lo mostará para tí.\n",
        "\n",
        "`python src/dataset.py charcorruption`\n",
        "\n",
        "No se solicita una respuesta escrita en esta tarea"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhiYlWHSYCeq"
      },
      "source": [
        "### f. (10 points) Preentrenamiento, ajuste fino y hacer predicciones (Presupuesto de 2 horas de entrenamiento)\n",
        "\n",
        "Ahora complete la parte de *preentrenamiento* de `run.py`, el cual preentrenará el modelo sobre la tarea de *span corruption*\n",
        "\n",
        "Adicionalmente, modifique su parte *finetune* para manejar el ajuste fino \"con preentrenamiento\". En particular, si el directorio del modelo preentrenado es provisto por consola, luego cargar este comando antes de ajustar finamente en la tarea de predicción nombre-lugar de nacimiento.\n",
        "\n",
        "Preentrenar tu modeo con wiki.txt (deberá tomar aproximadamente 2 hs), ajustarla finamente en NameDataset y evalúala.\n",
        "\n",
        "Específicamente, deberías ser capaz de ejecutar los siguientes 3 comandos:\n",
        "(No preocuparse si el costo se ve en una bandeja en la mitad del preentrenamiento, eventualmente descenderá)\n",
        "```\n",
        "#Preentrenamiento del modelo\n",
        "python src/run.py pretrain vanilla wiki.txt \\\n",
        "    --writing_params_path vanilla.pretrain.params\n",
        "\n",
        "#Finetune the model\n",
        "python src/run.py finetune vanilla wiki.txt \\\n",
        "    --reading_params_path vanilla.pretrain.params \\\n",
        "    --writing_params_path vanilla.finetune.params \\\n",
        "    --finetune_corpus_path birth_places_train.tsv\n",
        "\n",
        "#Evaluate on the dev set; write to disk\n",
        "    --reading_params_path vanilla.finetune.params \\\n",
        "    --eval_corpus_path birth_dev.tsv \\\n",
        "    --outputs_path vanilla.pretrain.dev.predictions\n",
        "\n",
        "#Evaluate on the test set; write to disk\n",
        "    --reading_params_path vanilla.finetune.params \\\n",
        "    --eval_corpus_path birth_test_inputs.tsv \\\n",
        "    --outputs_path vanilla.pretrain.test.predictions\n",
        "```\n",
        "Reportar el Accuracy del `dev`set. Esperamos que este sea al menos 10% y esperamos una Accuracy similar al set de test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eyxBYi7b3fi"
      },
      "source": [
        "### g. (10 points) Investigar! Escriba e intente la variante Sythesizer (Presupuesto de 2 hs para preentrenar)\n",
        "\n",
        "Ahora cambiaremos la arquitectura del Transfomer. Específicamente el módulo de **self-attention**\n",
        "\n",
        "Mientras que hemos utilizado la función de puntaje de self-attention basado en producto interno, esto requiere una computación intensiva cuadrática en la longitud de la secuencia.\n",
        "Esto se debe a que en cada cálculo se realiza el producto interno de $\\mathcal{l}^2$ pares de vectores de palabras.\n",
        "\n",
        "La atención Synthesized es una alternativa muy reciente que tiene los beneficios potenciales eliminando este producto interno. Es una idea prometedora que nos lleva a preguntar \"Qué es lo importante/correcto sobre la arquitectura Transformers, del cual podremos mejorar los aspectos de ella?\"\n",
        "\n",
        "En `Attention.py` implemente el método `forward()` de `SynthesizerAttention`, el cual implementa una variante del synthesizer propuesto en el paper citado.\n",
        "\n",
        "El provisto `CausalSelfAttention` implementa la siguiente atención para cada cabezal del multihead attention:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okIA17bhh1tA"
      },
      "source": [
        "Sea $X\\in\\mathcal{R}^{l\\times d}$ (con $l$ el tamaño del bloque y $d$ la dimensionalidad total, $d/h$ es la dimensionalidad por cabeza)\n",
        "\n",
        "**Obs.** Estas dimensionalidades no incluyen la dimensión de minibatch\n",
        "\n",
        "Sea $Q, K, V \\in \\mathcal{R}^{d\\times d/h}$.\n",
        "\n",
        "Luego la salida del cabezal de self-attention es:\n",
        "\n",
        "$$Y_i = softmax(\\frac{(X Q_i)(X K_i)^T}{\\sqrt{d/h} }(X V_i))$$\n",
        "\n",
        "Donde $Y_i\\in\\mathcal{R}^{l\\times d/h}$. \n",
        "\n",
        "Luego la salida de self-attention es una transformación lineal de la concatenación de los cabezales.\n",
        "\n",
        "$$Y = [Y_1 ; \\dots; Y_h] A$$\n",
        "\n",
        "Donde $A\\in \\mathcal{R}^{d\\times d}$ y $[Y_1;\\dots;Y_h] \\in \\mathcal{R}^{l\\times d}$. \n",
        "El código también incluye capas dropout que no hemos escrito aquí. Sugerimos ver el código provisto y observar cómo es implementada esta función en pytorch.\n",
        "\n",
        "Tu trabajo consiste en implementar la siguiente variante de Atención. En vez de la ecuación de $Y_i$, implemente la siguiente atención de Synthesizer:\n",
        "\n",
        "$$Y_i = softmax(ReLU(X A_i + b_1) B_i + b_2) (X V_i)$$\n",
        "\n",
        "Donde $A_i\\in \\mathcal{R}^{d\\times d/h}$, $B_i\\in\\mathcal{R}^{d/h \\times l}$ y $V_i \\in \\mathcal{R}^{d\\times d/h}$.\n",
        "\n",
        "**Pista:** Copiar la clase CausalSelfAttention, y modificarla minimamente.\n",
        "\n",
        "Una forma de interpretar esto es la siguiente:\n",
        "* El término $(X Q_i)(X K_i)^T$ es una matriz $l\\times l$ de puntajes de atención, calculadas como todos los productos internos de todos los pares entre word-embeddings.\n",
        "* La variante de Synthesizer evita que todos los pares de producto interno y directamente calcula la matriz de $l\\times l$ de puntajes de atención, mapeando cada vector d-dimensional en cada Cabeza para $X$ hasta un vector l-dimensional de vectores de pesos de atención desnormalizado.\n",
        "\n",
        "En el resto del código en el directorio `src/` modifique su modelo para soportar el uso tanto de CausalSelfAttention o SynthesizerAttention. \n",
        "Añada la posibilidad de elegir entre estas variantes según se escoja \"Vanilla\" o \"Synthesizer\" por línea de comandos. (Ver sección marcada en [part g] en `src/run.py`)\n",
        "Eres libre de implementar esta funcionalidad de la forma que desees, mientras soporte esos argumentos de consola."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0YsDXfAdo0J"
      },
      "source": [
        "A continuación están los comandos de consola que tu código debe soportar para poder preentrenar el modelo, ajustarlo finamente y hacer predicciones sobre los set de dev y test.\n",
        "\n",
        "Notar que el proceso de preentrenamiento tomará aproximadamente 2 hs.\n",
        "```\n",
        "#Preentrenar el modelo \n",
        "python src/run.py pretrain synthesizer wiki.txt \\\n",
        "    --writing_params_path synthesizer.pretrain.params\n",
        "\n",
        "#finetune the model\n",
        "python src/run.py finetune synthesizer wiki.txt\n",
        "    --reading_params_path synthesizer.pretrain.params \\\n",
        "    --writing_params_path synthesizer.finetune.params \\\n",
        "    --finetune_corpus_path birth_places_traing.tsv\n",
        "\n",
        "#Evaluate on the dev set; write to disk\n",
        "python src/run.py evaluate synthesizer wiki.txt \\\n",
        "    --reading_params_path synthesizer.finetune.params \\\n",
        "    --eval_corpus_path birth_dev.tsv \\\n",
        "    --outputs_path synthesizer.pretrain.dev.predictions\n",
        "\n",
        "#Evaluate on the test set; write to disk\n",
        "python src/run.py evaluate synthesizer wiki.txt \\\n",
        "    --reading_params_path synthesizer.finetune.params \\\n",
        "    --eval_corpus_path birth_test_inputs.tsv \\\n",
        "    --outputs_path synthesizer.pretrain.test.predictions\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJ55lXSscLdu"
      },
      "source": [
        "Reporte el Accuracy de tu modelo de atención *synthesizer* en la predicción de fechas de nacimiento sobre `birth_deb.tsv` luego de entrenar y ajustar finamente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UIb9bNRcLuE"
      },
      "source": [
        "#### i. (8 points) Puntuaremos tu modelo según obtenga un Accuracy del 5% en el set de testeo.\n",
        "Obtendremos las predicciones del modelo las predicciones de testeo utilizando el script de arriba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7O-gRHwc9gz"
      },
      "source": [
        "#### ii. (2 points) Por qué podría la self-attention de *synthesizer* no ser capaz de hacer en una sola capa? Qué puede hacer la atención key-querry-value?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG0xFl8COwFm"
      },
      "source": [
        "# 3 Consideraciones en el conocimiento pre-entrenado (5 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HYV07CqQGr5"
      },
      "source": [
        "### a. (1 point) Sintéticamente explique por qué el modelo preentrenado (vainilla) es capaz de obtener un Accuracy superior al 10%, cuando el modelo no preentrenado no pudo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXOvVgC0Qb31"
      },
      "source": [
        "### b. (2 points) Observar algunas predicciones correctas del modelo preentrenado y ajustado finamente del modelo \"Vainilla\" así también como algunos errores.\n",
        "\n",
        "Creemos que encontrarás imposible distinguir, a simple vista, cuando el modelo obtuvo la respuesta correcta o se inventó una respuesta.\n",
        "\n",
        "Considere las implicaciones de esto para un usuario final que utilice diferentes componentes preentrenados NLP.\n",
        "\n",
        "Traer dos razones por la que la indeterminación del comportamiento del modelo podría traer preocupaciones en tales aplicaciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxOz485NRRQT"
      },
      "source": [
        "### c. (2 points) Si tu modelo no ve el nombre en la hora de preentrenamiento, y la persona no fue vista en el ajuste fino.\n",
        "\n",
        "No es posible que podamos saber en donde nació. Sin embargo, nuestro modelo producirá una salida para el lugar de nacimiento.\n",
        "\n",
        "Concretamente, Describir una estrategia que podría utilizar tu modelo para predecir el lugar de nacimiento para el nombre de la persona y una razón de por qué esto genera preocupación al uso en tales aplicaciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhWUT6j9OwJz"
      },
      "source": [
        "# Referecias\n",
        "\n",
        "1. Radford, Narasimhan, Salimans y Sutskever. \"Improving language understanding with unsupervised learning\" Technical report, OpenAI (2018)\n",
        "\n",
        "2. Raffel, Shazeer, Roberts, Lee, Narang, Matena, Zhou, Li y Liu. \"Exploring the limits of transfer learning with unified text-to-text transformer\". Journal of machine learning research 21, 14 (2020), 1-67\n",
        "\n",
        "3. Tay, Bahri, Metzler, Juan, Zhao y Zheng. \"Synthesizer: Rethinking self-attention in transformers models\". arXiv preprint: 2005.00743 (2020). "
      ]
    }
  ]
}